{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from data_loader import prepare_ml_pipeline\n",
    "from matrix_factor import BiasedMF, train_mf\n",
    "from heater import train_heater, save_heater_embeddings\n",
    "from item_debias.main import load_data, train\n",
    "from dataclasses import dataclass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_pipeline(data_path: str = \"MovieLens1M\", \n",
    "                  batch_size: int = 1024,\n",
    "                  device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Set up and run the complete pipeline with proper error handling and logging\"\"\"\n",
    "    \n",
    "    # Set default dtype\n",
    "    torch.set_default_dtype(torch.float32)\n",
    "    \n",
    "    # 1. Ensure data path exists\n",
    "    data_dir = Path(data_path)\n",
    "    if not data_dir.exists():\n",
    "        raise FileNotFoundError(f\"Data directory {data_path} not found\")\n",
    "\n",
    "    try:\n",
    "        # 2. Load and prepare data\n",
    "        print(\"Loading data...\")\n",
    "        ml_data, train_loader, valid_loader, test_loader = prepare_ml_pipeline(\n",
    "            data_path=data_path,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "        # 3. Train base model\n",
    "        print(\"Training base model...\")\n",
    "        base_model = BiasedMF(\n",
    "            num_users=ml_data.n_users,\n",
    "            num_items=ml_data.n_items,\n",
    "            embedding_dim=100,\n",
    "            reg=0.0001\n",
    "        ).to(device)\n",
    "        \n",
    "        trained_base = train_mf(\n",
    "            model=base_model,\n",
    "            train_loader=train_loader,\n",
    "            num_epochs=1,\n",
    "            lr=0.001,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # 4. Train Heater\n",
    "        print(\"Training Heater model...\")\n",
    "        heater = train_heater(\n",
    "            ml_data=ml_data,\n",
    "            base_model=trained_base,\n",
    "            batch_size=batch_size,\n",
    "            num_epochs=1,\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        # 5. Save embeddings\n",
    "        print(\"Saving Heater embeddings...\")\n",
    "        save_dir = Path(data_path)\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "        save_heater_embeddings(\n",
    "            heater=heater,\n",
    "            ml_data=ml_data,\n",
    "            base_model=trained_base,\n",
    "            save_path=str(save_dir),\n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'ml_data': ml_data,\n",
    "            'base_model': trained_base,\n",
    "            'heater_model': heater,\n",
    "            'loaders': (train_loader, valid_loader, test_loader)\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in pipeline: {str(e)}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model: nn.Module,\n",
    "                  data_loader: torch.utils.data.DataLoader,\n",
    "                  device: str) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate model on given data loader\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for users, items, ratings in data_loader:\n",
    "            users = users.to(device)\n",
    "            items = items.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "            \n",
    "            output = model(users, items)\n",
    "            loss = criterion(output.preds, ratings)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Dataset loaded: 700146 train, 100021 validation, 200042 test\n",
      "Sparsity: 0.04468\n",
      "Training base model...\n",
      "Training Heater model...\n",
      "Saving Heater embeddings...\n",
      "Saved embeddings to MovieLens1M\n"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "data = setup_pipeline()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
