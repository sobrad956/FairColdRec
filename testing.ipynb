{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "from data_loader import prepare_ml_pipeline, MovieLensData, MovieLensDataset\n",
    "from matrix_factor import BiasedMF, train_mf\n",
    "from debiasing import train_debiasing_model, DebiasingModel\n",
    "from dropoutnet import DeepCF, train_dropoutnet\n",
    "from evaluator import ndcg_calc_base, ndcg_calc_dropout, ndcg_calc_debiased, ndcg_calc_sampled, ndcg_calc_dropout_sampled, ndcg_calc_debiased_sampled\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_pipeline(device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Complete evaluation pipeline with DropoutNet and debiasing\"\"\"\n",
    "    \n",
    "    # Define evaluation parameters\n",
    "    k_values = [15,30]\n",
    "    \n",
    "\n",
    "    dropoutnet_params = {\n",
    "        'model_select': [800, 400],\n",
    "        'rank_out': 200,\n",
    "        'dropout_rate': 0.5,\n",
    "        'batch_size': 1000,\n",
    "        'n_scores_per_user': 2500,\n",
    "        'data_batch_size': 1000,\n",
    "        'max_data_per_step': 50000,\n",
    "        'num_epochs': 1,\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    "    \n",
    "    #Params from https://github.com/Zziwei/Fairness-in-Cold-Start-Recommendation/blob/main/Scale/main.py\n",
    "    debiasing_params = {\n",
    "        'model_select': [100],\n",
    "        'alpha': 4.0,\n",
    "        'batch_size': 50,\n",
    "        'num_epochs': 1,\n",
    "        'reg': 0.00001\n",
    "    }\n",
    "    \n",
    "    # 1. Load and prepare data\n",
    "    print(\"Loading data...\")\n",
    "    ml_data, train_loader, valid_loader, test_loader = prepare_ml_pipeline(cold_start=True)\n",
    "    #evaluator = RecommenderEvaluator(ml_data)\n",
    "    \n",
    "    # 2. Train and evaluate base model\n",
    "    print(\"\\nTraining base model...\")\n",
    "    base_model = BiasedMF(ml_data.n_users, ml_data.n_items).to(device)\n",
    "    base_model = train_mf(model = base_model, train_loader= train_loader, val_loader= valid_loader, ml_data= ml_data, num_epochs=1, lr = .01)\n",
    "    \n",
    "    base_ndcgs, base_prec, base_recall, final_mdg, mdg_anal = ndcg_calc_base(base_model, test_loader, ml_data, k_values=k_values)\n",
    "    print(f\"Base NDCGS: {base_ndcgs}\")\n",
    "    #print(f\"Final MDG: {mdg_anal['all']['mean']}, min10: {mdg_anal['bottom_10']['mean']}, min20: {mdg_anal['bottom_20']['mean']}, top10: {mdg_anal['top_10']['mean']}\")\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #3. Train and evaluate DropoutNet model\n",
    "    print(\"\\nTraining DropoutNet model...\")\n",
    "    dropoutnet = train_dropoutnet(\n",
    "        ml_data=ml_data,\n",
    "        base_model=base_model,\n",
    "        val_loader=valid_loader,\n",
    "        test_loader=test_loader,\n",
    "        **dropoutnet_params,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    print(\"\\nEvaluating DropoutNet model...\")\n",
    "    dropout_ndcgs, drop_mdg, drop_mdg_anal = ndcg_calc_dropout_sampled(base_model, dropoutnet, test_loader, ml_data, k_values = k_values)\n",
    "    print(f\"Dropout NDCGs {dropout_ndcgs}\")\n",
    "    print(f\"Final MDG: {drop_mdg_anal['all']['mean']}, min10: {drop_mdg_anal['bottom_10']['mean']}, min20: {drop_mdg_anal['bottom_20']['mean']}, top10: {drop_mdg_anal['top_10']['mean']}\")\n",
    "\n",
    "    \n",
    "    # 4. Train and evaluate debiasing model\n",
    "    print(\"\\nTraining debiasing model...\")\n",
    "    debiasing_model = train_debiasing_model(\n",
    "        base_model=dropoutnet,\n",
    "        original_mf=base_model,\n",
    "        ml_data=ml_data,\n",
    "        **debiasing_params,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"\\nEvaluating debiased model...\")\n",
    "    debiased_ndcgs, debiased_prec, debiased_rec, debiased_mdg, debiased_mdg_anal = ndcg_calc_debiased_sampled(dropoutnet, base_model, debiasing_model,test_loader,ml_data,k_values=k_values)\n",
    "    \n",
    "    print(f\"Debiased NDCGs {debiased_ndcgs}\")\n",
    "    print(f\"Final MDG: {debiased_mdg_anal['all']['mean']}, min10: {debiased_mdg_anal['bottom_10']['mean']}, min20: {debiased_mdg_anal['bottom_20']['mean']}, top10: {debiased_mdg_anal['top_10']['mean']}\")\n",
    "    \n",
    "   \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Dataset loaded with cold_start=True:\n",
      "Train: 692958 interactions\n",
      "Valid: 94109 interactions\n",
      "Test: 213142 interactions\n",
      "Cold-start statistics:\n",
      "Valid items not in train: 370\n",
      "Test items not in train: 741\n",
      "\n",
      "Training base model...\n",
      "Epoch 1 - Avg Loss: 1.7364 - Avg Train NDCG: 0.6936 - Avg Test NDCG: 0.0148\n",
      "Epoch 1 - Train Precision: 0.0000 - Train Recall: 0.0000 - Avg Test Prec: 0.0092 - Avg Tet Rec: 0.023722199298856106\n",
      "Base NDCGS: [0.7241947991582373, 0.7692262617376064]\n",
      "\n",
      "Training DropoutNet model...\n",
      "Initializing DropoutNet training...\n",
      "\tu_concat rank=100\n",
      "\tv_concat rank=118\n",
      "Starting training for 1 epochs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackklawitter/Documents/Rutgers/FairAI/FairColdRec/dropoutnet.py:590: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Uin = torch.tensor(u_emb_expanded[batch_u_idx], device=device)\n",
      "/Users/jackklawitter/Documents/Rutgers/FairAI/FairColdRec/dropoutnet.py:591: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  Vin = torch.tensor(i_emb_expanded[batch_i_idx], device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100: Loss = 0.0092\n",
      "Step 200: Loss = 0.0086\n",
      "Step 300: Loss = 0.0081\n",
      "Epoch 1/1: Average Loss = 0.0132\n",
      "\n",
      "Training completed!\n",
      "\n",
      "Evaluating DropoutNet model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ndcg_calc_dropout_sampled() got an unexpected keyword argument 'ks'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mrun_evaluation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 58\u001b[0m, in \u001b[0;36mrun_evaluation_pipeline\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m     48\u001b[0m dropoutnet \u001b[38;5;241m=\u001b[39m train_dropoutnet(\n\u001b[1;32m     49\u001b[0m     ml_data\u001b[38;5;241m=\u001b[39mml_data,\n\u001b[1;32m     50\u001b[0m     base_model\u001b[38;5;241m=\u001b[39mbase_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     55\u001b[0m )\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEvaluating DropoutNet model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 58\u001b[0m dropout_ndcgs, drop_mdg, drop_mdg_anal \u001b[38;5;241m=\u001b[39m \u001b[43mndcg_calc_dropout_sampled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropoutnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mk_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDropout NDCGs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdropout_ndcgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal MDG: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrop_mdg_anal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, min10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrop_mdg_anal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom_10\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, min20: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrop_mdg_anal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbottom_20\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, top10: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdrop_mdg_anal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtop_10\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: ndcg_calc_dropout_sampled() got an unexpected keyword argument 'ks'"
     ]
    }
   ],
   "source": [
    "test = run_evaluation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
