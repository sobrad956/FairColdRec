{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_loader import prepare_ml_pipeline\n",
    "from matrix_factor import BiasedMF, train_mf\n",
    "from debiasing import train_debiasing_model\n",
    "from dropoutnet import train_dropoutnet\n",
    "from evaluator import ndcg_calc_sampled, ndcg_calc_dropout_sampled, ndcg_calc_debiased_sampled, evaluate_split\n",
    "import evaluator as ev\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_ndcg_by_positives(ndcg_scores, n_positives, avg_positives):\n",
    "\n",
    "    norm_factor = avg_positives / n_positives  # will be < 1 for cold users (more positives), > 1 for warm users (fewer positives)\n",
    "    return [score * norm_factor for score in ndcg_scores]\n",
    "\n",
    "def analyze_positive_distribution(ml_data, cold_users, warm_users):\n",
    "    \"\"\"\n",
    "    Analyze the distribution of positive ratings between train and test sets\n",
    "    for both cold and warm users\n",
    "    \"\"\"\n",
    "    train_positives_warm = (ml_data.train_data['user_idx'].isin(warm_users) & (ml_data.train_data['rating'] >= 4)).sum()\n",
    "    test_positives_warm = (ml_data.test_data['user_idx'].isin(warm_users) & (ml_data.test_data['rating'] >= 4)).sum()\n",
    "    total_positives_warm = train_positives_warm + test_positives_warm\n",
    "\n",
    "    train_positives_cold = (ml_data.train_data['user_idx'].isin(cold_users) & (ml_data.train_data['rating'] >= 4)).sum()\n",
    "    test_positives_cold = (ml_data.test_data['user_idx'].isin(cold_users) & (ml_data.test_data['rating'] >= 4)).sum()\n",
    "    total_positives_cold = train_positives_cold + test_positives_cold\n",
    "\n",
    "    print(\"\\nPositive Ratings Distribution Analysis:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"Warm Users:\")\n",
    "    print(f\"  Train positives: {train_positives_warm}\")\n",
    "    print(f\"  Test positives: {test_positives_warm}\")\n",
    "    print(f\"  Total positives: {total_positives_warm}\")\n",
    "    print(f\"  Ratio in test: {test_positives_warm/total_positives_warm:.2%}\")\n",
    "    print(f\"  Average per user: {total_positives_warm/len(warm_users):.2f}\")\n",
    "\n",
    "    print(f\"\\nCold Users:\")\n",
    "    print(f\"  Train positives: {train_positives_cold}\")\n",
    "    print(f\"  Test positives: {test_positives_cold}\")\n",
    "    print(f\"  Total positives: {total_positives_cold}\")\n",
    "    print(f\"  Ratio in test: {test_positives_cold/total_positives_cold:.2%}\")\n",
    "    print(f\"  Average per user: {total_positives_cold/len(cold_users):.2f}\")\n",
    "\n",
    "    return {\n",
    "        'warm': {\n",
    "            'train': train_positives_warm,\n",
    "            'test': test_positives_warm,\n",
    "            'total': total_positives_warm,\n",
    "            'test_ratio': test_positives_warm/total_positives_warm\n",
    "        },\n",
    "        'cold': {\n",
    "            'train': train_positives_cold,\n",
    "            'test': test_positives_cold,\n",
    "            'total': total_positives_cold,\n",
    "            'test_ratio': test_positives_cold/total_positives_cold\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def run_evaluation_pipeline(device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Complete evaluation pipeline with DropoutNet and debiasing\"\"\"\n",
    "    \n",
    "    # Define evaluation parameters\n",
    "    k_values = [15,30]\n",
    "    \n",
    "\n",
    "    dropoutnet_params = {\n",
    "        'model_select': [800, 400],\n",
    "        'rank_out': 200,\n",
    "        'dropout_rate': 0.5,\n",
    "        'batch_size': 1000,\n",
    "        'n_scores_per_user': 2500,\n",
    "        'data_batch_size': 1000,\n",
    "        'max_data_per_step': 50000,\n",
    "        'num_epochs': 25,\n",
    "        'learning_rate': 0.001\n",
    "    }\n",
    "    \n",
    "    #Params from https://github.com/Zziwei/Fairness-in-Cold-Start-Recommendation/blob/main/Scale/main.py\n",
    "    debiasing_params = {\n",
    "        'model_select': [100],\n",
    "        'alpha': 4.0,\n",
    "        'batch_size': 50,\n",
    "        'num_epochs': 100,\n",
    "        'reg': 0.000001\n",
    "    }\n",
    "    \n",
    "    # 1. Load and prepare data\n",
    "    print(\"Loading data...\")\n",
    "    ml_data, train_loader, valid_loader, test_loader = prepare_ml_pipeline(cold_start=False)\n",
    "  \n",
    "\n",
    "    # Get cold/warm user split\n",
    "    cold_users, warm_users = ev.get_user_split(ml_data.train_data, ml_data.test_data)\n",
    "    cold_items, warm_items = ev.get_item_split(ml_data.train_data, ml_data.test_data)\n",
    "    \n",
    "    # Analyze positive distribution\n",
    "    #distribution_stats = analyze_positive_distribution(ml_data, cold_users, warm_users)\n",
    "    \n",
    "    # Calculate normalized NDCG\n",
    "    cold_positives = len(ml_data.test_data[ml_data.test_data['user_idx'].isin(cold_users)]['rating'] >= 4)\n",
    "    warm_positives = len(ml_data.test_data[ml_data.test_data['user_idx'].isin(warm_users)]['rating'] >= 4)\n",
    "    avg_positives = (cold_positives + warm_positives) / 2\n",
    "    \n",
    "    \n",
    "    # 2. Train and evaluate base model\n",
    "    print(\"\\nTraining base model...\")\n",
    "    base_model = BiasedMF(ml_data.n_users, ml_data.n_items).to(device)\n",
    "    base_model = train_mf(model = base_model, train_loader= train_loader, val_loader= valid_loader, ml_data= ml_data, num_epochs=25, lr = .01)\n",
    "    \n",
    "    base_ndcgs, base_prec, base_recall = ndcg_calc_sampled(base_model, test_loader, ml_data, k_values=k_values)\n",
    "    final_mdg, mdg_anal = ev.mdg_calc_base(base_model, test_loader, ml_data)\n",
    "    print(f\"Base NDCGS: {base_ndcgs}\")\n",
    "    print(f\"Final MDG: {mdg_anal['all']['mean']}, min10: {mdg_anal['bottom_10']['mean']}, min20: {mdg_anal['bottom_20']['mean']}, top10: {mdg_anal['top_10']['mean']}\")\n",
    "    base_cold_warm = ev.analyze_mdg_with_splits(final_mdg, cold_items, warm_items)\n",
    "    print(\"\\nBase Model MDG Analysis:\")\n",
    "    ev.print_mdg_analysis(base_cold_warm)  \n",
    "    \n",
    "    print(\"\\nEvaluating base model...\")\n",
    "    base_metrics = evaluate_split(\n",
    "        eval_model=base_model,\n",
    "        test_loader=test_loader,\n",
    "        ml_data=ml_data,\n",
    "        cold_users=cold_users,\n",
    "        warm_users=warm_users,\n",
    "        k_values=k_values,\n",
    "        evaluation_func=ndcg_calc_sampled\n",
    "    )\n",
    "    \n",
    "    print(\"\\nBase Model Results:\")\n",
    "    print(f\"Base NDCGs: {base_ndcgs}\")\n",
    "    print(\"\\nBase Model Results:\")\n",
    "    print(f\"Cold Users (n={base_metrics.n_cold_users}):\")\n",
    "    normalized_cold_ndcgs = normalize_ndcg_by_positives(base_metrics.cold_users.ndcg, cold_positives, avg_positives)\n",
    "    print(f\"  Original NDCG@{k_values}: {base_metrics.cold_users.ndcg}\")\n",
    "    print(f\"  Normalized NDCG@{k_values}: {normalized_cold_ndcgs}\")\n",
    "    \n",
    "    print(f\"Warm Users (n={base_metrics.n_warm_users}):\")\n",
    "    normalized_warm_ndcgs = normalize_ndcg_by_positives(base_metrics.warm_users.ndcg, warm_positives, avg_positives)\n",
    "    print(f\"  Original NDCG@{k_values}: {base_metrics.warm_users.ndcg}\")\n",
    "    print(f\"  Normalized NDCG@{k_values}: {normalized_warm_ndcgs}\")\n",
    "\n",
    "    \n",
    "    #3. Train and evaluate DropoutNet model\n",
    "    print(\"\\nTraining DropoutNet model...\")\n",
    "    dropoutnet = train_dropoutnet(\n",
    "        ml_data=ml_data,\n",
    "        base_model=base_model,\n",
    "        val_loader=valid_loader,\n",
    "        test_loader=test_loader,\n",
    "        **dropoutnet_params,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    print(\"\\nEvaluating DropoutNet model...\")\n",
    "    dropout_ndcgs, drop_mdg, drop_mdg_anal = ndcg_calc_dropout_sampled(base_model, dropoutnet, test_loader, ml_data, k_values = k_values)\n",
    "    drop_mdg, drop_mdg_anal = ev.mdg_calc_dropout(dropoutnet, base_model, test_loader,ml_data)\n",
    "    print(f\"Dropout NDCGs {dropout_ndcgs}\")\n",
    "    print(f\"Final MDG: {drop_mdg_anal['all']['mean']}, min10: {drop_mdg_anal['bottom_10']['mean']}, min20: {drop_mdg_anal['bottom_20']['mean']}, top10: {drop_mdg_anal['top_10']['mean']}\")\n",
    "     # Analyze cold vs warm for dropout model\n",
    "    dropout_cold_warm = ev.analyze_mdg_with_splits(drop_mdg, cold_items, warm_items)\n",
    "\n",
    "    print(\"\\nDebiased Model MDG Analysis:\")\n",
    "    ev.print_mdg_analysis(dropout_cold_warm)\n",
    "    \n",
    "    print(\"\\nEvaluating DropoutNet model...\")\n",
    "    dropout_metrics = evaluate_split(\n",
    "        eval_model=dropoutnet,  # Base model needed for embeddings\n",
    "        test_loader=test_loader,\n",
    "        ml_data=ml_data,\n",
    "        cold_users=cold_users,\n",
    "        warm_users=warm_users,\n",
    "        k_values=k_values,\n",
    "        evaluation_func=ndcg_calc_dropout_sampled,\n",
    "        base_model=base_model  # Changed parameter name to avoid conflict\n",
    "    )\n",
    "    \n",
    "    print(\"\\nDropoutNet Results:\")\n",
    "    print(f\"Dropout NDCGs: {dropout_ndcgs}\")\n",
    "    print(f\"Cold Users (n={dropout_metrics.n_cold_users}):\")\n",
    "    normalized_cold_ndcgs = normalize_ndcg_by_positives(dropout_metrics.cold_users.ndcg, cold_positives, avg_positives)\n",
    "    print(f\"  Original NDCG@{k_values}: {dropout_metrics.cold_users.ndcg}\")\n",
    "    print(f\"  Normalized NDCG@{k_values}: {normalized_cold_ndcgs}\")\n",
    "    \n",
    "    print(f\"Warm Users (n={dropout_metrics.n_warm_users}):\")\n",
    "    normalized_warm_ndcgs = normalize_ndcg_by_positives(dropout_metrics.warm_users.ndcg, warm_positives, avg_positives)\n",
    "    print(f\"  Original NDCG@{k_values}: {dropout_metrics.warm_users.ndcg}\")\n",
    "    print(f\"  Normalized NDCG@{k_values}: {normalized_warm_ndcgs}\")\n",
    "    \n",
    "    # 4. Train and evaluate debiasing model\n",
    "    print(\"\\nTraining debiasing model...\")\n",
    "    debiasing_model = train_debiasing_model(\n",
    "        base_model=dropoutnet,\n",
    "        original_mf=base_model,\n",
    "        ml_data=ml_data,\n",
    "        **debiasing_params,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"\\nEvaluating debiased model...\")\n",
    "    debiased_ndcgs, debiased_prec, debiased_rec = ndcg_calc_debiased_sampled(dropoutnet, base_model, debiasing_model,test_loader,ml_data,k_values=k_values)\n",
    "    debiased_mdg, debiased_mdg_anal = ev.mdg_calc_debiased(dropoutnet, base_model, debiasing_model, test_loader, ml_data)\n",
    "    print(f\"Debiased NDCGs {debiased_ndcgs}\")\n",
    "    print(f\"Final MDG: {debiased_mdg_anal['all']['mean']}, min10: {debiased_mdg_anal['bottom_10']['mean']}, min20: {debiased_mdg_anal['bottom_20']['mean']}, top10: {debiased_mdg_anal['top_10']['mean']}\")\n",
    "    # Analyze cold vs warm for debiased model\n",
    "    debiased_cold_warm = ev.analyze_mdg_with_splits(\n",
    "        debiased_mdg,\n",
    "        cold_items, warm_items\n",
    "    )\n",
    "\n",
    "    print(\"\\nDebiased Model MDG Analysis:\")\n",
    "    ev.print_mdg_analysis(debiased_cold_warm)\n",
    "\n",
    "    print(\"\\nEvaluating debiased model...\")\n",
    "    debiased_metrics = evaluate_split(\n",
    "        eval_model=debiasing_model,  # Base model for embeddings\n",
    "        test_loader=test_loader,\n",
    "        ml_data=ml_data,\n",
    "        cold_users=cold_users,\n",
    "        warm_users=warm_users,\n",
    "        k_values=k_values,\n",
    "        evaluation_func=ndcg_calc_debiased_sampled,\n",
    "        prior_model=dropoutnet,\n",
    "        original_mf=base_model\n",
    "    )\n",
    "    \n",
    "    print(\"\\nDebiased Model Results:\")\n",
    "    print(f\"Debiased NDCGs: {debiased_ndcgs}\")\n",
    "    print(f\"Cold Users (n={debiased_metrics.n_cold_users}):\")\n",
    "    normalized_cold_ndcgs = normalize_ndcg_by_positives(debiased_metrics.cold_users.ndcg, cold_positives, avg_positives)\n",
    "    print(f\"  Original NDCG@{k_values}: {debiased_metrics.cold_users.ndcg}\")\n",
    "    print(f\"  Normalized NDCG@{k_values}: {normalized_cold_ndcgs}\")\n",
    "    \n",
    "    print(f\"Warm Users (n={debiased_metrics.n_warm_users}):\")\n",
    "    normalized_warm_ndcgs = normalize_ndcg_by_positives(debiased_metrics.warm_users.ndcg, warm_positives, avg_positives)\n",
    "    print(f\"  Original NDCG@{k_values}: {debiased_metrics.warm_users.ndcg}\")\n",
    "    print(f\"  Normalized NDCG@{k_values}: {normalized_warm_ndcgs}\")\n",
    "    \n",
    "    return {\n",
    "        'base': base_metrics,\n",
    "        'dropout': dropout_metrics,\n",
    "        'debiased': debiased_metrics\n",
    "    }\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "test = run_evaluation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
