{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from data_loader import prepare_ml_pipeline, MovieLensData, MovieLensDataset\n",
    "from matrix_factor import BiasedMF, train_mf\n",
    "from debiasing import train_debiasing_model, DebiasingModel\n",
    "from heater import train_heater, save_heater_embeddings\n",
    "#from evaluator import RecommenderEvaluator\n",
    "from dropoutnet import DeepCF, train_dropoutnet\n",
    "from new_evaluator import ndcg_calc_base, ndcg_calc_dropout, evaluate_recommendations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_evaluation_pipeline(device: str = 'cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    \"\"\"Complete evaluation pipeline with DropoutNet and debiasing\"\"\"\n",
    "    \n",
    "    # Define evaluation parameters\n",
    "    k_values = [5, 10, 20, 50]\n",
    "    dropoutnet_params = {\n",
    "        'model_select': [800, 400],\n",
    "        'rank_out': 200,\n",
    "        'dropout_rate': 0.5,\n",
    "        'batch_size': 100,           \n",
    "        'n_scores_per_user': 100,    \n",
    "        'data_batch_size': 500,      \n",
    "        'max_data_per_step': 10000,  \n",
    "        'num_epochs': 50,\n",
    "        'learning_rate': 0.005\n",
    "    }\n",
    "    \n",
    "    debiasing_params = {\n",
    "        'model_select': [100],\n",
    "        'alpha': 4.0,\n",
    "        'batch_size': 50,\n",
    "        'num_epochs': 1,\n",
    "        'reg': 1e-5\n",
    "    }\n",
    "    \n",
    "    # 1. Load and prepare data\n",
    "    print(\"Loading data...\")\n",
    "    ml_data, train_loader, valid_loader, test_loader = prepare_ml_pipeline(cold_start=False)\n",
    "    #evaluator = RecommenderEvaluator(ml_data)\n",
    "    \n",
    "    # 2. Train and evaluate base model\n",
    "    print(\"\\nTraining base model...\")\n",
    "    base_model = BiasedMF(ml_data.n_users, ml_data.n_items).to(device)\n",
    "    base_model = train_mf(base_model, train_loader, num_epochs=200)\n",
    "    \n",
    "    base_ndcgs = ndcg_calc_base(base_model, test_loader, ml_data)\n",
    "    print(f\"Base NDCGS: {base_ndcgs}\")\n",
    "    \n",
    "    # 3. Train and evaluate DropoutNet model\n",
    "    print(\"\\nTraining DropoutNet model...\")\n",
    "    dropoutnet = train_dropoutnet(\n",
    "        ml_data=ml_data,\n",
    "        base_model=base_model,\n",
    "        **dropoutnet_params,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    \n",
    "    print(\"\\nEvaluating DropoutNet model...\")\n",
    "    dropout_ndcgs = ndcg_calc_dropout(base_model, dropoutnet, test_loader, ml_data, ks = [5,10,20,50])\n",
    "    print(f\"Dropout NDCGs {dropout_ndcgs}\")\n",
    "    \n",
    "    # 4. Train and evaluate debiasing model\n",
    "    print(\"\\nTraining debiasing model...\")\n",
    "    debiasing_model = train_debiasing_model(\n",
    "        base_model=dropoutnet,  # Using DropoutNet as base\n",
    "        ml_data=ml_data,\n",
    "        **debiasing_params,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    print(\"\\nEvaluating debiased model...\")\n",
    "    debiased_ndcgs = ndcg_calc_base(dropoutnet, test_loader)\n",
    "    \n",
    "    print(f\"Debiased NDCGs {dropout_ndcgs}\")\n",
    "    \n",
    "    # # 5. Analyze popularity bias\n",
    "    # print(\"\\nAnalyzing popularity bias...\")\n",
    "    # # For DropoutNet\n",
    "    # dropoutnet_bias_metrics = evaluator.analyze_popularity_bias(\n",
    "    #     model=dropoutnet,  # Your trained DropoutNet model\n",
    "    #     base_model=base_model,\n",
    "    #     device=device\n",
    "    # )\n",
    "    # print(\"\\nDropoutNet Bias Analysis Results:\")\n",
    "    # for metric, value in dropoutnet_bias_metrics.items():\n",
    "    #     print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "    # debiased_bias_metrics = evaluator.analyze_popularity_bias(\n",
    "    #     model=debiasing_model,\n",
    "    #     base_model=dropoutnet,\n",
    "    #     k=20,\n",
    "    #     device=device\n",
    "    # )\n",
    "    \n",
    "    # print(\"\\nDropoutNet Bias Analysis Results:\")\n",
    "    # for metric, value in dropoutnet_bias_metrics.items():\n",
    "    #     print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    # print(\"\\nDebiased Model Bias Analysis Results:\")\n",
    "    # for metric, value in debiased_bias_metrics.items():\n",
    "    #     print(f\"{metric}: {value:.4f}\")\n",
    "        \n",
    "    # # Store bias metrics for plotting\n",
    "    # evaluator.bias_metrics = {\n",
    "    #     'dropoutnet': dropoutnet_bias_metrics,\n",
    "    #     'debiased': debiased_bias_metrics\n",
    "    # }\n",
    "    \n",
    "    # 6. Plot comparisons\n",
    "    # print(\"\\nGenerating comparison plots...\")\n",
    "    # evaluator.plot_performance_comparison(\n",
    "    #     k_values=k_values,\n",
    "    #     save_path='evaluation_results.png'\n",
    "    # )\n",
    "    \n",
    "    #return evaluator\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Dataset loaded with cold_start=False:\n",
      "Train: 700146 interactions\n",
      "Valid: 100021 interactions\n",
      "Test: 200042 interactions\n",
      "\n",
      "Training base model...\n",
      "Epoch 5/200 - Avg Loss: 0.9434\n",
      "Epoch 10/200 - Avg Loss: 0.8787\n",
      "Epoch 15/200 - Avg Loss: 0.8674\n",
      "Epoch 20/200 - Avg Loss: 0.8640\n",
      "Epoch 25/200 - Avg Loss: 0.8627\n",
      "Epoch 30/200 - Avg Loss: 0.8615\n",
      "Epoch 35/200 - Avg Loss: 0.8609\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test \u001b[38;5;241m=\u001b[39m \u001b[43mrun_evaluation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 34\u001b[0m, in \u001b[0;36mrun_evaluation_pipeline\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTraining base model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m base_model \u001b[38;5;241m=\u001b[39m BiasedMF(ml_data\u001b[38;5;241m.\u001b[39mn_users, ml_data\u001b[38;5;241m.\u001b[39mn_items)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 34\u001b[0m base_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m base_ndcgs \u001b[38;5;241m=\u001b[39m ndcg_calc_base(base_model, test_loader, ml_data)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBase NDCGS: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_ndcgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Rutgers/FairAI/FairColdRec/matrix_factor.py:135\u001b[0m, in \u001b[0;36mtrain_mf\u001b[0;34m(model, train_loader, num_epochs, lr, device)\u001b[0m\n\u001b[1;32m    132\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    133\u001b[0m num_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 135\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mratings\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Move to device\u001b[39;49;00m\n\u001b[1;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43muser_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43mitem_ids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mitem_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/fairness/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/fairness/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fairness/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/fairness/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/fairness/lib/python3.11/multiprocessing/queues.py:122\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rlock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# unserialize the data after having released the lock\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _ForkingPickler\u001b[38;5;241m.\u001b[39mloads(res)\n",
      "File \u001b[0;32m~/miniconda3/envs/fairness/lib/python3.11/site-packages/torch/multiprocessing/reductions.py:560\u001b[0m, in \u001b[0;36mrebuild_storage_filename\u001b[0;34m(cls, manager, handle, size, dtype)\u001b[0m\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m storage\u001b[38;5;241m.\u001b[39m_shared_decref()\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 560\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_shared_filename_cpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    562\u001b[0m     byte_size \u001b[38;5;241m=\u001b[39m size \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test = run_evaluation_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [5, 10, 20, 50]\n",
    "device = 'cpu'\n",
    "\n",
    "# 1. Load and prepare data\n",
    "print(\"Loading data...\")\n",
    "ml_data, train_loader, valid_loader, test_loader = prepare_ml_pipeline(cold_start=False)\n",
    "evaluator = RecommenderEvaluator(ml_data)\n",
    "\n",
    "# 2. Train and evaluate base model\n",
    "print(\"\\nTraining base model...\")\n",
    "base_model = BiasedMF(ml_data.n_users, ml_data.n_items).to(device)\n",
    "base_model = train_mf(base_model, train_loader, num_epochs=1)\n",
    "\n",
    "print(\"\\nEvaluating base model...\")\n",
    "base_metrics = evaluator.evaluate_base_mf(\n",
    "    model=base_model,\n",
    "    data_loader=test_loader,\n",
    "    k_values=k_values,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(\"\\nBase Model Results:\")\n",
    "for k in k_values:\n",
    "    print(f\"NDCG@{k}: {base_metrics[f'ndcg@{k}']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_evaluator import ndcg_calc\n",
    "\n",
    "k_values = [5, 10, 20, 50]\n",
    "device = 'cpu'\n",
    "\n",
    "# 1. Load and prepare data\n",
    "print(\"Loading data...\")\n",
    "ml_data, train_loader, valid_loader, test_loader = prepare_ml_pipeline(cold_start=True)\n",
    "evaluator = RecommenderEvaluator(ml_data)\n",
    "\n",
    "\n",
    "# 2. Train and evaluate base model\n",
    "print(\"\\nTraining base model...\")\n",
    "base_model = BiasedMF(ml_data.n_users, ml_data.n_items).to(device)\n",
    "base_model = train_mf(base_model, train_loader, num_epochs=20)\n",
    "\n",
    "ndcgs = ndcg_calc(base_model, test_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fairness",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
